{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import netCDF4\n",
    "import gzip\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.wkt\n",
    "from shapely.geometry import shape\n",
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, MultiLineString\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENV VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/helvecioneto/01_IARA/RADAR/iara_beta_v6/output/S201409070000_E201409100000_VDBZc_T20_L5_SPLTTrue_MERGTrue_TCORTrue_PCORFalse.zip'\n",
    "DATA_PATH = '/home/helvecioneto/SINAPSE_01/DADOS/sbandradar/'\n",
    "VAR_NAME = 'DBZc'\n",
    "LEVEL = 5\n",
    "THRESHOLD = [20,35,40]\n",
    "OUTPUT = '../output/'\n",
    "NC_OUTPUT = '../output/data/'\n",
    "# CLUSTERS = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### READ TRACK FROM PATH\n",
    "def read_track(path):\n",
    "    zip_file = ZipFile(path)\n",
    "    for f in zip_file.infolist():\n",
    "        if f.filename.endswith('.csv') and 'FINAL' in f.filename:\n",
    "            tracking_df = pd.read_csv(zip_file.open(f))\n",
    "    return tracking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPEN NETCDF\n",
    "def open_file(file_path):\n",
    "    try:\n",
    "        with gzip.open(file_path) as gz:\n",
    "            with netCDF4.Dataset('dummy', mode='r', memory=gz.read()) as nc:\n",
    "                data = nc.variables[VAR_NAME][0][LEVEL][:].filled()\n",
    "                data[data == -9999.] = np.NAN\n",
    "        return data\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAMILY GENERATOR\n",
    "def create_fam(df):\n",
    "    ## REORGANIZE FAM BY MULTINDEX\n",
    "    df = df.groupby('uid').apply(lambda x: x.sort_values([\"uid\"], ascending = False))\n",
    "    index_list = df.index.tolist()\n",
    "    new_list = []\n",
    "    for i in index_list:\n",
    "        new_list.append(('Fam_'+str(i[0]),i[1]))\n",
    "    mux = pd.MultiIndex.from_tuples(new_list)\n",
    "    df.index = mux\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET LAT LONG MATRIX\n",
    "def get_latlong_matrix(file_path):\n",
    "    with gzip.open(file_path) as gz:\n",
    "        with netCDF4.Dataset('dummy', mode='r', memory=gz.read()) as nc:\n",
    "            data_var = nc.variables.keys()\n",
    "            for k in data_var:\n",
    "                if k.lower().startswith('lat'):\n",
    "                    llat = k\n",
    "                elif k.lower().startswith('lon'):\n",
    "                    llon = k\n",
    "            lon = nc.variables[llon][:]\n",
    "            lat = nc.variables[llat][:]\n",
    "    return lon,lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERATE PATCH FILES\n",
    "def generate_path_files(df,DATA_PATH):\n",
    "    for i,row in df.iterrows():\n",
    "        file = str(pd.to_datetime(row.timestamp).strftime(DATA_PATH+'%Y/%m/sbmn_cappi_%Y%m%d_%H%M.nc.gz'))\n",
    "        df.loc[i,'nc_file'] = file\n",
    "        cluster = pd.to_datetime(row.timestamp).strftime('clusters/%Y%m%d_%H%M%S_clu.npz')\n",
    "        df.loc[i,'cluster_file'] = cluster\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OPEN CLUSTERS BY DBSCAN\n",
    "def open_cluster(path,file_path):\n",
    "    try:\n",
    "        zip_file = ZipFile(path)\n",
    "        cluster = np.load(zip_file.open(file_path))['arr_0']\n",
    "        return cluster\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate angle of Linestring\n",
    "def angle(x):\n",
    "    p1 = list(shape(x).coords)[0]\n",
    "    p2 = list(shape(x).coords)[1]\n",
    "\n",
    "    rad_ = math.atan2(p2[1]-p1[1], p2[0]-p1[0])\n",
    "    direction = math.degrees(rad_)\n",
    "\n",
    "    if direction < 0:\n",
    "        direction = direction + 360\n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp\n",
    "# uid     -> identificador unico\n",
    "# time    -> timeindex\n",
    "\n",
    "# lat lon -> centroid\n",
    "\n",
    "# size_20    -> tamanho do sistema\n",
    "# total_size_30    -> tamanho do sistema\n",
    "# total_size_40    -> tamanho do sistema\n",
    "\n",
    "# dsize   -> Delta área\n",
    "\n",
    "# mean_ref_20 -> \n",
    "# mean_total_ref_30 -> \n",
    "# mean_total_ref_40 ->\n",
    "\n",
    "# angle_20 ->\n",
    "# avg_angle_30 ->\n",
    "# avg_angle_40 ->\n",
    "\n",
    "# vel_20_orig ->\n",
    "# vel_20_cor ->\n",
    "\n",
    "# avg_vel_30 ->\n",
    "# avg_vel_40 ->\n",
    "\n",
    "# n_cluster_30 ->\n",
    "# n_cluster_40 ->\n",
    "\n",
    "# status -> \n",
    "# lifetime -> delta_t\n",
    "\n",
    "\n",
    "# MAX_REFLECT -> Máxima refletivida do cluster no tempo t\n",
    "# DMAX_REFLECT -> Diferença entre a max (t-1) com (t)\n",
    "# DMEAN_REFLECT -> Média\n",
    "\n",
    "#### DÚVIDA, PODE CALCULAR DIRETO?\n",
    "\n",
    "#### UM NOTEBOOK PARA CONVERTER TRACKING PARA FAMILY (No mínimo 2 clusters por familia)\n",
    "#### UM NOTEBOOK PARA VISUALIZAR FAMILIY E CONSULTAR CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dbz(df,threshold,path):\n",
    "    for i, row in df.iterrows():\n",
    "        ### GET REFLECT AND PIXEL SIZES\n",
    "        cluster_matrix = open_cluster(path,row.cluster_file)\n",
    "        dbz_matrix = open_file(row.nc_file)\n",
    "        if cluster_matrix is not None and dbz_matrix is not None:\n",
    "            for t in range(len(threshold)):\n",
    "                clt_matrix = cluster_matrix[:,:,t]\n",
    "                x,y = np.where(clt_matrix == row.id_t)\n",
    "                dbz_list = dbz_matrix[x,y]\n",
    "                if len(dbz_list) > 0:\n",
    "                    ### MEAN REFLECT\n",
    "                    mmh6 = np.mean(10**(dbz_list/10))\n",
    "                    dbz_mean = (10*np.log10(mmh6))\n",
    "                    dbz_max = np.max(dbz_list)\n",
    "\n",
    "                    if t == 0:\n",
    "                        df.loc[i,'mean_ref_'+str(threshold[t])] = dbz_mean\n",
    "                        df.loc[i,'max_ref_'+str(threshold[t])] = dbz_max\n",
    "                        df.loc[i,'size_'+str(threshold[t])] = len(x)\n",
    "                    else:\n",
    "                        df.loc[i,'mean_total_ref_'+str(threshold[t])] = dbz_mean\n",
    "                        df.loc[i,'total_size_'+str(threshold[t])] = int(len(x))\n",
    "        else:\n",
    "            del cluster_matrix,dbz_matrix\n",
    "        \n",
    "        ### GET ORIG ANGLE AND VELM\n",
    "        if row.linestring != '-1':\n",
    "            for t in range(len(threshold)):\n",
    "                if t == 0:\n",
    "                    df.loc[i,'angle_'+str(threshold[t])+'_cor'] = row.angle\n",
    "                    df.loc[i,'angle_'+str(threshold[t])+'_orig'] = angle(shapely.wkt.loads(row.linestring))\n",
    "                    \n",
    "                    ## VELM\n",
    "                    df.loc[i,'vel_'+str(threshold[t])+'_orig'] = (row['length'] * 2) / 0.2\n",
    "                    df.loc[i,'vel_'+str(threshold[t])+'_cor'] = row.velm\n",
    "                else:\n",
    "                    df.loc[i,'avg_angle_'+str(threshold[t])] = row['internal_angle_mean_'+str(threshold[t])]\n",
    "                    df.loc[i,'avg_vel_'+str(threshold[t])] = row['internal_velm_'+str(threshold[t])]\n",
    "                    \n",
    "        ### GET LON LAT\n",
    "        if row.centroid_t != '-1':\n",
    "            point = list(shape(shapely.wkt.loads(row.centroid_t)).coords)[0]\n",
    "            p0,p1 = int(np.round(point[0])),int(np.round(point[1]))\n",
    "            long = LON[p1][p0]\n",
    "            latg = LAT[p1][p0]\n",
    "            \n",
    "            df.loc[i,'lat'] = latg\n",
    "            df.loc[i,'lon'] = long\n",
    "            df.loc[i,'p0'] = p0\n",
    "            df.loc[i,'p1'] = p1  \n",
    "            \n",
    "        ### GET NUMBER OF CLUSTERS\n",
    "        for t in threshold[1:]:\n",
    "            if row['n_poly_'+str(t)] == -1:\n",
    "                df.loc[i,'n_cluster_'+str(t)] = 0\n",
    "            else:\n",
    "                df.loc[i,'n_cluster_'+str(t)] = row['n_poly_'+str(t)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRACK DATA FRAME\n",
    "track_df = read_track(PATH)\n",
    "track_df = generate_path_files(track_df,DATA_PATH)\n",
    "LON,LAT = get_latlong_matrix(track_df.iloc[0]['nc_file'])\n",
    "\n",
    "to_fam_df = calc_dbz(track_df,THRESHOLD,PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mount trajectory\n",
    "for i,row in to_fam_df.iterrows():\n",
    "    if '-1' not in row['centroid_tp'] and '-1' not in row['centroid_t']:\n",
    "        traj = LineString([shapely.wkt.loads(row['centroid_tp']),shapely.wkt.loads(row['centroid_t'])])\n",
    "        to_fam_df.loc[i,'trajectory'] = traj.wkt\n",
    "    else:\n",
    "        to_fam_df.loc[i,'trajectory'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_columns = ['timestamp','time','uid','id_t','lat','lon','p0','p1']\n",
    "for t in range(len(THRESHOLD)):\n",
    "    if t == 0:\n",
    "        used_columns.append('size_'+str(THRESHOLD[t]))\n",
    "        used_columns.append('mean_ref_'+str(THRESHOLD[t]))\n",
    "        used_columns.append('max_ref_'+str(THRESHOLD[t]))\n",
    "        used_columns.append('angle_'+str(THRESHOLD[t])+'_orig')\n",
    "        used_columns.append('angle_'+str(THRESHOLD[t])+'_cor')\n",
    "        used_columns.append('vel_'+str(THRESHOLD[t])+'_orig')\n",
    "        used_columns.append('vel_'+str(THRESHOLD[t])+'_cor')\n",
    "    else:\n",
    "        used_columns.append('mean_total_ref_'+str(THRESHOLD[t]))\n",
    "        used_columns.append('total_size_'+str(THRESHOLD[t]))\n",
    "        used_columns.append('n_cluster_'+str(THRESHOLD[t]))\n",
    "        used_columns.append('avg_angle_'+str(THRESHOLD[t]))\n",
    "        used_columns.append('avg_vel_'+str(THRESHOLD[t]))\n",
    "        \n",
    "used_columns.append('status')\n",
    "used_columns.append('delta_t')\n",
    "used_columns.append('nc_file')\n",
    "used_columns.append('cluster_file')\n",
    "\n",
    "# used_columns.append('line_'+str(THRESHOLD[0]))\n",
    "# used_columns.append('line_'+str(THRESHOLD[1]))\n",
    "# used_columns.append('line_'+str(THRESHOLD[2]))\n",
    "\n",
    "used_columns.append('geom_intersect')\n",
    "used_columns.append('geom_'+str(THRESHOLD[0]))\n",
    "used_columns.append('geom_'+str(THRESHOLD[1]))\n",
    "used_columns.append('geom_'+str(THRESHOLD[2]))\n",
    "used_columns.append('trajectory')\n",
    "used_columns.append('vector_'+str(THRESHOLD[0]))\n",
    "used_columns.append('vector_'+str(THRESHOLD[1]))\n",
    "used_columns.append('vector_'+str(THRESHOLD[2]))\n",
    "\n",
    "\n",
    "to_fam_df['delta_t'] = to_fam_df['lifetime']\n",
    "\n",
    "## GEOMETRIES\n",
    "to_fam_df['geom_intersect'] = to_fam_df['intersect_geom']\n",
    "to_fam_df['geom_'+str(THRESHOLD[0])] = to_fam_df['geometry_t']\n",
    "to_fam_df['geom_'+str(THRESHOLD[1])] = to_fam_df['geom_'+str(THRESHOLD[1])]\n",
    "to_fam_df['geom_'+str(THRESHOLD[2])] = to_fam_df['geom_'+str(THRESHOLD[2])]\n",
    "\n",
    "\n",
    "to_fam_df['vector_'+str(THRESHOLD[0])] = to_fam_df['linestring']\n",
    "to_fam_df['vector_'+str(THRESHOLD[1])] = to_fam_df['internal_linestring_'+str(THRESHOLD[1])]\n",
    "to_fam_df['vector_'+str(THRESHOLD[2])] = to_fam_df['internal_linestring_'+str(THRESHOLD[2])]\n",
    "        \n",
    "to_fam_df = to_fam_df[used_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine(df):\n",
    "    df_copy = df\n",
    "    #### REPLACE 0 to NAN\n",
    "    df_copy = df_copy[df_copy.columns[6:]].replace(0,np.nan)\n",
    "    #### REPLACE -1 to NAN\n",
    "    df_copy = df_copy.replace(-1,np.nan)\n",
    "    #### REPLACE '-1' to NAN\n",
    "    df_copy = df_copy.replace('-1',np.nan)\n",
    "    df_final = pd.concat([df[df.columns[:6]],df_copy],axis=1)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_poly(geom,latitude,longitude):\n",
    "    x,y = geom.exterior.coords.xy\n",
    "    points = []\n",
    "    for v in range(len(x)):\n",
    "        points.append([longitude[int(np.round(y[v]))][int(np.round(x[v]))],latitude[int(np.round(y[v]))][int(np.round(x[v]))]])\n",
    "    poly = Polygon(list(zip(np.array(points)[:,0],np.array(points)[:,1])))\n",
    "    return poly\n",
    "\n",
    "def trans_multipoly(geom,latitude,longitude):\n",
    "    polys2 = []\n",
    "    for gg in geom:\n",
    "        x,y = gg.exterior.coords.xy\n",
    "        points = []\n",
    "        for v in range(len(x)):\n",
    "            points.append([longitude[int(np.round(y[v]))][int(np.round(x[v]))],latitude[int(np.round(y[v]))][int(np.round(x[v]))]])\n",
    "        polys2.append(Polygon(list(zip(np.array(points)[:,0],np.array(points)[:,1]))))\n",
    "    return MultiPolygon(polys2)\n",
    "\n",
    "def trans_lines(geom,latitude,longitude):\n",
    "    x,y = geom.xy\n",
    "    p = []\n",
    "    for v in range(len(x)):\n",
    "        p.append(Point([longitude[int(np.round(y[v]))][int(np.round(x[v]))],latitude[int(np.round(y[v]))][int(np.round(x[v]))]]))\n",
    "    return LineString(p)\n",
    "\n",
    "def trans_multilines(geom,latitude,longitude):\n",
    "    lines2 = []\n",
    "    for gg in geom:\n",
    "        x,y = gg.xy\n",
    "        p = []\n",
    "        for v in range(len(x)):\n",
    "            p.append(Point([longitude[int(np.round(y[v]))][int(np.round(x[v]))],latitude[int(np.round(y[v]))][int(np.round(x[v]))]]))\n",
    "        lines2.append(LineString(p))\n",
    "    return MultiLineString(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_geometries(df_frame,gcols,lat,lon):\n",
    "    \n",
    "    ## Replace Null geometries\n",
    "    df_frame[gcols] = df_frame[gcols].replace(['-1.0', '0',np.nan], 'GEOMETRYCOLLECTION EMPTY')\n",
    "    \n",
    "    ### Transform to shapely\n",
    "    for g in gcols:\n",
    "        df_frame[g] = df_frame[g].astype(str).apply(shapely.wkt.loads)\n",
    "        \n",
    "        for geo in df_frame[g].index:\n",
    "            ## Transpolygons\n",
    "            if type(df_frame.loc[geo][g]) == Polygon:\n",
    "                geometry = trans_poly(df_frame.loc[geo][g],lat,lon)\n",
    "                df_frame.loc[geo,g] = geometry.wkt\n",
    "                \n",
    "            elif type(df_frame.loc[geo][g]) == MultiPolygon:\n",
    "                geometry = trans_multipoly(df_frame.loc[geo][g],lat,lon)\n",
    "                df_frame.loc[geo,g] = geometry.wkt\n",
    "                \n",
    "            elif type(df_frame.loc[geo][g]) == LineString:\n",
    "                geometry = trans_lines(df_frame.loc[geo][g],lat,lon)\n",
    "                df_frame.loc[geo,g] = geometry.wkt\n",
    "                \n",
    "            elif type(df_frame.loc[geo][g]) == MultiLineString:\n",
    "                geometry = trans_multilines(df_frame.loc[geo][g],lat,lon)\n",
    "                df_frame.loc[geo,g] = geometry.wkt\n",
    "                \n",
    "            else:\n",
    "                df_frame.loc[geo,g] = 'GEOMETRYCOLLECTION EMPTY'  \n",
    "    \n",
    "    return df_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE DIRsused_columns.append('line_'+str(THRESHOLD[0]))\n",
    "# used_columns.append('line_'+str(THRESHOLD[1]))\n",
    "# used_columns.append('line_'+str(THRESHOLD[2]))\n",
    "Path(OUTPUT).mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT+'clusters').mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT+'data').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRACT CLUSTERS\n",
    "with ZipFile(PATH, 'r') as zipObj:\n",
    "    listOfFileNames = zipObj.namelist()\n",
    "    for fileName in listOfFileNames:\n",
    "        if 'clusters/' in fileName:\n",
    "            zipObj.extract(fileName, OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### COPY NC_FILES\n",
    "for i,row in to_fam_df.iterrows():\n",
    "#     print(str(NC_OUTPUT+Path(row.nc_file).name))\n",
    "#     print(OUTPUT+row.cluster_file)\n",
    "#     print('')\n",
    "#     print(OUTPUT[7:]+row.cluster_file,OUTPUT[7:]+'data/'+row.nc_file[27:])\n",
    "#     print(row.nc_file,OUTPUT[7:]+'../fam/data/'+row.nc_file[27:])\n",
    "    try:\n",
    "        copyfile(row.nc_file,str(NC_OUTPUT+Path(row.nc_file).name))\n",
    "        to_fam_df.loc[i,'nc_file'] = str(NC_OUTPUT+Path(row.nc_file).name)\n",
    "        to_fam_df.loc[i,'cluster_file'] = OUTPUT+row.cluster_file\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_cols = []\n",
    "for c in to_fam_df.columns:\n",
    "    if 'geom_' in c or 'line' in c or 'traj' in c or 'vect' in c:\n",
    "        geo_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fam_df = redefine(to_fam_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRANSLATE GEOMETRIES\n",
    "to_fam_df = trans_geometries(to_fam_df,geo_cols,LAT,LON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_df = create_fam(to_fam_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTER BY SIZE\n",
    "sized_fams = []\n",
    "for i,g in fam_df.groupby(level=0):\n",
    "    if len(g) >= 2:\n",
    "        sized_fams.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FINAL FRAME\n",
    "fam_df = fam_df.loc[sized_fams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CALCULATE DIFFERENCES\n",
    "for i,g in fam_df.groupby(level=0):\n",
    "    for t in range(len(THRESHOLD)):\n",
    "        if t == 0:\n",
    "            fam_df.loc[i,'dsize_'+str(THRESHOLD[t])] = g['size_'+str(THRESHOLD[t])].diff()\n",
    "            fam_df.loc[i,'dmean_ref_'+str(THRESHOLD[t])] = g['mean_ref_'+str(THRESHOLD[t])].diff()\n",
    "        else:\n",
    "            fam_df.loc[i,'dtotal_size_'+str(THRESHOLD[t])] = g['total_size_'+str(THRESHOLD[t])].diff()\n",
    "            fam_df.loc[i,'dmean_total_ref_'+str(THRESHOLD[t])] = g['mean_total_ref_'+str(THRESHOLD[t])].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fam_df[geo_cols] = fam_df[geo_cols].replace(['-1.0', '0',np.nan], 'GEOMETRYCOLLECTION EMPTY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAVE PICKLE\n",
    "fam_df.to_pickle('tracking_compressed.pkl',compression='xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nc_file</th>\n",
       "      <th>cluster_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fam_0</th>\n",
       "      <th>0</th>\n",
       "      <td>../output/data/sbmn_cappi_20140907_0000.nc.gz</td>\n",
       "      <td>../output/clusters/20140907_000000_clu.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>../output/data/sbmn_cappi_20140907_0012.nc.gz</td>\n",
       "      <td>../output/clusters/20140907_001200_clu.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fam_1</th>\n",
       "      <th>1</th>\n",
       "      <td>../output/data/sbmn_cappi_20140907_0000.nc.gz</td>\n",
       "      <td>../output/clusters/20140907_000000_clu.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>../output/data/sbmn_cappi_20140907_0012.nc.gz</td>\n",
       "      <td>../output/clusters/20140907_001200_clu.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fam_10</th>\n",
       "      <th>20</th>\n",
       "      <td>../output/data/sbmn_cappi_20140907_0024.nc.gz</td>\n",
       "      <td>../output/clusters/20140907_002400_clu.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Fam_97</th>\n",
       "      <th>533</th>\n",
       "      <td>../output/data/sbmn_cappi_20140907_1900.nc.gz</td>\n",
       "      <td>../output/clusters/20140907_190000_clu.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>../output/data/sbmn_cappi_20140907_1912.nc.gz</td>\n",
       "      <td>../output/clusters/20140907_191200_clu.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>../output/data/sbmn_cappi_20140907_1924.nc.gz</td>\n",
       "      <td>../output/clusters/20140907_192400_clu.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fam_98</th>\n",
       "      <th>538</th>\n",
       "      <td>../output/data/sbmn_cappi_20140907_1900.nc.gz</td>\n",
       "      <td>../output/clusters/20140907_190000_clu.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>../output/data/sbmn_cappi_20140907_1912.nc.gz</td>\n",
       "      <td>../output/clusters/20140907_191200_clu.npz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1815 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  nc_file  \\\n",
       "Fam_0  0    ../output/data/sbmn_cappi_20140907_0000.nc.gz   \n",
       "       10   ../output/data/sbmn_cappi_20140907_0012.nc.gz   \n",
       "Fam_1  1    ../output/data/sbmn_cappi_20140907_0000.nc.gz   \n",
       "       11   ../output/data/sbmn_cappi_20140907_0012.nc.gz   \n",
       "Fam_10 20   ../output/data/sbmn_cappi_20140907_0024.nc.gz   \n",
       "...                                                   ...   \n",
       "Fam_97 533  ../output/data/sbmn_cappi_20140907_1900.nc.gz   \n",
       "       548  ../output/data/sbmn_cappi_20140907_1912.nc.gz   \n",
       "       566  ../output/data/sbmn_cappi_20140907_1924.nc.gz   \n",
       "Fam_98 538  ../output/data/sbmn_cappi_20140907_1900.nc.gz   \n",
       "       554  ../output/data/sbmn_cappi_20140907_1912.nc.gz   \n",
       "\n",
       "                                          cluster_file  \n",
       "Fam_0  0    ../output/clusters/20140907_000000_clu.npz  \n",
       "       10   ../output/clusters/20140907_001200_clu.npz  \n",
       "Fam_1  1    ../output/clusters/20140907_000000_clu.npz  \n",
       "       11   ../output/clusters/20140907_001200_clu.npz  \n",
       "Fam_10 20   ../output/clusters/20140907_002400_clu.npz  \n",
       "...                                                ...  \n",
       "Fam_97 533  ../output/clusters/20140907_190000_clu.npz  \n",
       "       548  ../output/clusters/20140907_191200_clu.npz  \n",
       "       566  ../output/clusters/20140907_192400_clu.npz  \n",
       "Fam_98 538  ../output/clusters/20140907_190000_clu.npz  \n",
       "       554  ../output/clusters/20140907_191200_clu.npz  \n",
       "\n",
       "[1815 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fam_df[['nc_file','cluster_file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>geom_intersect</th>\n",
       "      <th>geom_20</th>\n",
       "      <th>geom_35</th>\n",
       "      <th>geom_40</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>vector_20</th>\n",
       "      <th>vector_35</th>\n",
       "      <th>vector_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fam_13</th>\n",
       "      <th>155</th>\n",
       "      <td>MULTIPOLYGON (((-60.89051055908203 -2.42988395...</td>\n",
       "      <td>POLYGON ((-60.98067474365234 -2.73522067070007...</td>\n",
       "      <td>MULTIPOLYGON (((-60.90858840942383 -2.55562806...</td>\n",
       "      <td>MULTIPOLYGON (((-60.90858840942383 -2.55562806...</td>\n",
       "      <td>LINESTRING (-60.62072372436523 -2.322270631790...</td>\n",
       "      <td>LINESTRING (-60.62072372436523 -2.322270631790...</td>\n",
       "      <td>MULTILINESTRING ((-60.85437393188477 -2.178393...</td>\n",
       "      <td>MULTILINESTRING ((-60.85438537597656 -2.196358...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fam_24</th>\n",
       "      <th>153</th>\n",
       "      <td>POLYGON ((-58.58712387084961 -3.70485043525695...</td>\n",
       "      <td>POLYGON ((-58.55072021484375 -3.95630025863647...</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "      <td>LINESTRING (-58.51511001586914 -3.704745292663...</td>\n",
       "      <td>LINESTRING (-58.51511001586914 -3.704745292663...</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fam_29</th>\n",
       "      <th>156</th>\n",
       "      <td>POLYGON ((-59.72177505493164 -1.96308720111846...</td>\n",
       "      <td>POLYGON ((-59.82962036132812 -2.05293798446655...</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "      <td>LINESTRING (-59.68581008911133 -2.034943342208...</td>\n",
       "      <td>LINESTRING (-59.68581008911133 -2.034943342208...</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fam_30</th>\n",
       "      <th>154</th>\n",
       "      <td>MULTIPOLYGON (((-61.55714416503906 -3.34532546...</td>\n",
       "      <td>POLYGON ((-61.55714416503906 -3.34532546997070...</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "      <td>LINESTRING (-61.57480621337891 -3.129729747772...</td>\n",
       "      <td>LINESTRING (-61.57480621337891 -3.129729747772...</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               geom_intersect  \\\n",
       "Fam_13 155  MULTIPOLYGON (((-60.89051055908203 -2.42988395...   \n",
       "Fam_24 153  POLYGON ((-58.58712387084961 -3.70485043525695...   \n",
       "Fam_29 156  POLYGON ((-59.72177505493164 -1.96308720111846...   \n",
       "Fam_30 154  MULTIPOLYGON (((-61.55714416503906 -3.34532546...   \n",
       "\n",
       "                                                      geom_20  \\\n",
       "Fam_13 155  POLYGON ((-60.98067474365234 -2.73522067070007...   \n",
       "Fam_24 153  POLYGON ((-58.55072021484375 -3.95630025863647...   \n",
       "Fam_29 156  POLYGON ((-59.82962036132812 -2.05293798446655...   \n",
       "Fam_30 154  POLYGON ((-61.55714416503906 -3.34532546997070...   \n",
       "\n",
       "                                                      geom_35  \\\n",
       "Fam_13 155  MULTIPOLYGON (((-60.90858840942383 -2.55562806...   \n",
       "Fam_24 153                           GEOMETRYCOLLECTION EMPTY   \n",
       "Fam_29 156                           GEOMETRYCOLLECTION EMPTY   \n",
       "Fam_30 154                           GEOMETRYCOLLECTION EMPTY   \n",
       "\n",
       "                                                      geom_40  \\\n",
       "Fam_13 155  MULTIPOLYGON (((-60.90858840942383 -2.55562806...   \n",
       "Fam_24 153                           GEOMETRYCOLLECTION EMPTY   \n",
       "Fam_29 156                           GEOMETRYCOLLECTION EMPTY   \n",
       "Fam_30 154                           GEOMETRYCOLLECTION EMPTY   \n",
       "\n",
       "                                                   trajectory  \\\n",
       "Fam_13 155  LINESTRING (-60.62072372436523 -2.322270631790...   \n",
       "Fam_24 153  LINESTRING (-58.51511001586914 -3.704745292663...   \n",
       "Fam_29 156  LINESTRING (-59.68581008911133 -2.034943342208...   \n",
       "Fam_30 154  LINESTRING (-61.57480621337891 -3.129729747772...   \n",
       "\n",
       "                                                    vector_20  \\\n",
       "Fam_13 155  LINESTRING (-60.62072372436523 -2.322270631790...   \n",
       "Fam_24 153  LINESTRING (-58.51511001586914 -3.704745292663...   \n",
       "Fam_29 156  LINESTRING (-59.68581008911133 -2.034943342208...   \n",
       "Fam_30 154  LINESTRING (-61.57480621337891 -3.129729747772...   \n",
       "\n",
       "                                                    vector_35  \\\n",
       "Fam_13 155  MULTILINESTRING ((-60.85437393188477 -2.178393...   \n",
       "Fam_24 153                           GEOMETRYCOLLECTION EMPTY   \n",
       "Fam_29 156                           GEOMETRYCOLLECTION EMPTY   \n",
       "Fam_30 154                           GEOMETRYCOLLECTION EMPTY   \n",
       "\n",
       "                                                    vector_40  \n",
       "Fam_13 155  MULTILINESTRING ((-60.85438537597656 -2.196358...  \n",
       "Fam_24 153                           GEOMETRYCOLLECTION EMPTY  \n",
       "Fam_29 156                           GEOMETRYCOLLECTION EMPTY  \n",
       "Fam_30 154                           GEOMETRYCOLLECTION EMPTY  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fam_df.query('time == 20')[geo_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ## PRIMEIRA LINHA DO NOVO FRAME\n",
    "# inicial = track_df.iloc[[0]][['nc_file','cluster_file']]\n",
    "\n",
    "# cluster_matrix = open_cluster(PATH,inicial['cluster_file'].values[0])[:,:,0]\n",
    "# cluster_matrix[cluster_matrix == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### VISUALIZATION\n",
    "# plt.imshow(cluster_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### SELECT X Y FROM 'id_t'\n",
    "# x,y = np.where(cluster_matrix[:,:] == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## READ DBZ MATRIX FROM NETCDF\n",
    "# dbz_matrix = open_file(inicial['nc_file'].values[0])\n",
    "# # dbz_matrix[dbz_matrix < THRESHOLD[0]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## VISUALIZATION DBZ MATRIX\n",
    "# plt.imshow(dbz_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## VISUALIZATION\n",
    "# track_df.iloc[[0]][['timestamp','uid','id_t','global_mean_threshold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Tamanho do cluster',len(dbz_matrix[x,y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbz_list = dbz_matrix[x,y]\n",
    "\n",
    "# mmm6 = np.mean(10**(dbz_list/10))\n",
    "# dbz_mean = (10*np.log10(mmm6))\n",
    "# print('Resultado do código ->',dbz_mean,' dBZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_mmh =  np.mean((10**(dbz_list/10))/174.8)**(1/1.56)\n",
    "# mean_reflect = 10*np.log10(200*(mean_mmh**1.6))\n",
    "# mean_reflect = (mean_reflect)\n",
    "\n",
    "# mean_reflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         ### COMPARE FLAG AND NO FLAG\n",
    "#         no_flag_geoms = df_compare.loc[df_compare.timestamp == row.timestamp]\n",
    "#         for no,rowno in no_flag_geoms.iterrows():\n",
    "#             if rowno.geometry_t != '-1':\n",
    "#                 no_geom = shapely.wkt.loads(rowno.geometry_t)\n",
    "#                 actual_geom = shapely.wkt.loads(row['geometry_t'])\n",
    "#                 if actual_geom.equals(no_geom):\n",
    "#                     if row.velm != rowno.velm:\n",
    "#                         for t in range(len(threshold)):\n",
    "#                             print(row.velm,rowno.velm, '---- FAR: ',row.FAR_20,' -- FAR_NO',rowno.FAR_20)\n",
    "#                             df.loc[i,'total_size_'+str(threshold[t])] = len(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
